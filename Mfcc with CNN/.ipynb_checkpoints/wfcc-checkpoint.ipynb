{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:05:46.008961Z",
     "start_time": "2018-09-07T09:05:20.709191Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Saving vectors of label - 'Dutch': 100%|██████████| 50/50 [00:01<00:00, 43.57it/s]\n",
      "Saving vectors of label - 'Australian': 100%|██████████| 40/40 [00:00<00:00, 50.35it/s]\n",
      "Saving vectors of label - 'Nigerian': 100%|██████████| 79/79 [00:01<00:00, 41.37it/s]\n",
      "Saving vectors of label - 'French': 100%|██████████| 68/68 [00:01<00:00, 43.27it/s]\n",
      "Saving vectors of label - 'Spanish': 100%|██████████| 204/204 [00:05<00:00, 39.42it/s]\n",
      "Saving vectors of label - 'British': 100%|██████████| 69/69 [00:01<00:00, 46.65it/s]\n",
      "Saving vectors of label - 'Chinese': 100%|██████████| 165/165 [00:04<00:00, 38.58it/s]\n",
      "Saving vectors of label - 'Canadian': 100%|██████████| 45/45 [00:00<00:00, 50.65it/s]\n",
      "Saving vectors of label - 'Arabic': 100%|██████████| 154/154 [00:04<00:00, 35.23it/s]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from wfcc_pre_process import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 9\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 9\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:05:46.057255Z",
     "start_time": "2018-09-07T09:05:46.012499Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adagrad (),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:10.791483Z",
     "start_time": "2018-09-07T09:05:46.059854Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 524 samples, validate on 350 samples\n",
      "Epoch 1/50\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 5.6412 - acc: 0.1336 - val_loss: 2.1562 - val_acc: 0.1514\n",
      "Epoch 2/50\n",
      "524/524 [==============================] - 0s 885us/step - loss: 2.1546 - acc: 0.1870 - val_loss: 2.0736 - val_acc: 0.1857\n",
      "Epoch 3/50\n",
      "524/524 [==============================] - 1s 981us/step - loss: 2.1328 - acc: 0.2233 - val_loss: 2.0605 - val_acc: 0.2371\n",
      "Epoch 4/50\n",
      "524/524 [==============================] - 0s 885us/step - loss: 2.0304 - acc: 0.2424 - val_loss: 2.0820 - val_acc: 0.1771\n",
      "Epoch 5/50\n",
      "524/524 [==============================] - 0s 876us/step - loss: 2.0765 - acc: 0.2042 - val_loss: 2.0243 - val_acc: 0.2429\n",
      "Epoch 6/50\n",
      "524/524 [==============================] - 0s 884us/step - loss: 1.9992 - acc: 0.2557 - val_loss: 2.0183 - val_acc: 0.2514\n",
      "Epoch 7/50\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 2.0164 - acc: 0.2252 - val_loss: 2.0067 - val_acc: 0.2257\n",
      "Epoch 8/50\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 1.9531 - acc: 0.2366 - val_loss: 1.9806 - val_acc: 0.2571\n",
      "Epoch 9/50\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 1.9154 - acc: 0.2767 - val_loss: 1.9796 - val_acc: 0.2400\n",
      "Epoch 10/50\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 1.8954 - acc: 0.2901 - val_loss: 1.9674 - val_acc: 0.2657\n",
      "Epoch 11/50\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 1.8378 - acc: 0.3511 - val_loss: 2.0468 - val_acc: 0.1971\n",
      "Epoch 12/50\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 1.8673 - acc: 0.3683 - val_loss: 2.0225 - val_acc: 0.2371\n",
      "Epoch 13/50\n",
      "524/524 [==============================] - 1s 963us/step - loss: 1.7848 - acc: 0.3683 - val_loss: 1.9864 - val_acc: 0.2657\n",
      "Epoch 14/50\n",
      "524/524 [==============================] - 0s 935us/step - loss: 1.7228 - acc: 0.3702 - val_loss: 2.0276 - val_acc: 0.2429\n",
      "Epoch 15/50\n",
      "524/524 [==============================] - 0s 853us/step - loss: 1.6975 - acc: 0.3855 - val_loss: 1.9902 - val_acc: 0.2200\n",
      "Epoch 16/50\n",
      "524/524 [==============================] - 0s 826us/step - loss: 1.6704 - acc: 0.3779 - val_loss: 2.0367 - val_acc: 0.2714\n",
      "Epoch 17/50\n",
      "524/524 [==============================] - 0s 846us/step - loss: 1.6133 - acc: 0.4084 - val_loss: 2.0412 - val_acc: 0.2486\n",
      "Epoch 18/50\n",
      "524/524 [==============================] - 0s 817us/step - loss: 1.5537 - acc: 0.4504 - val_loss: 2.0288 - val_acc: 0.2457\n",
      "Epoch 19/50\n",
      "524/524 [==============================] - 0s 832us/step - loss: 1.4712 - acc: 0.4752 - val_loss: 2.0727 - val_acc: 0.2743\n",
      "Epoch 20/50\n",
      "524/524 [==============================] - 0s 822us/step - loss: 1.4491 - acc: 0.5019 - val_loss: 2.0797 - val_acc: 0.2400\n",
      "Epoch 21/50\n",
      "524/524 [==============================] - 0s 861us/step - loss: 1.3811 - acc: 0.5115 - val_loss: 2.0261 - val_acc: 0.2971\n",
      "Epoch 22/50\n",
      "524/524 [==============================] - 0s 850us/step - loss: 1.3400 - acc: 0.5248 - val_loss: 2.1200 - val_acc: 0.2743\n",
      "Epoch 23/50\n",
      "524/524 [==============================] - 0s 833us/step - loss: 1.3103 - acc: 0.5420 - val_loss: 2.0530 - val_acc: 0.2914\n",
      "Epoch 24/50\n",
      "524/524 [==============================] - 0s 855us/step - loss: 1.1999 - acc: 0.5935 - val_loss: 2.1243 - val_acc: 0.2571\n",
      "Epoch 25/50\n",
      "524/524 [==============================] - 0s 827us/step - loss: 1.1249 - acc: 0.6126 - val_loss: 2.3017 - val_acc: 0.2571\n",
      "Epoch 26/50\n",
      "524/524 [==============================] - 0s 842us/step - loss: 1.0666 - acc: 0.6260 - val_loss: 2.2215 - val_acc: 0.2514\n",
      "Epoch 27/50\n",
      "524/524 [==============================] - 0s 829us/step - loss: 1.0207 - acc: 0.6641 - val_loss: 2.2332 - val_acc: 0.2543\n",
      "Epoch 28/50\n",
      "524/524 [==============================] - 0s 860us/step - loss: 0.9543 - acc: 0.6527 - val_loss: 2.4166 - val_acc: 0.2657\n",
      "Epoch 29/50\n",
      "524/524 [==============================] - 0s 854us/step - loss: 1.0228 - acc: 0.6527 - val_loss: 2.4362 - val_acc: 0.2686\n",
      "Epoch 30/50\n",
      "524/524 [==============================] - 0s 822us/step - loss: 0.9442 - acc: 0.6679 - val_loss: 2.4133 - val_acc: 0.2171\n",
      "Epoch 31/50\n",
      "524/524 [==============================] - 0s 890us/step - loss: 0.8489 - acc: 0.7137 - val_loss: 2.4681 - val_acc: 0.2371\n",
      "Epoch 32/50\n",
      "524/524 [==============================] - 0s 831us/step - loss: 0.7929 - acc: 0.7290 - val_loss: 2.5031 - val_acc: 0.2543\n",
      "Epoch 33/50\n",
      "524/524 [==============================] - 0s 859us/step - loss: 0.7564 - acc: 0.7385 - val_loss: 2.5788 - val_acc: 0.2600\n",
      "Epoch 34/50\n",
      "524/524 [==============================] - 0s 861us/step - loss: 0.7045 - acc: 0.7824 - val_loss: 2.5422 - val_acc: 0.2543\n",
      "Epoch 35/50\n",
      "524/524 [==============================] - 0s 851us/step - loss: 0.6393 - acc: 0.8015 - val_loss: 2.9888 - val_acc: 0.2429\n",
      "Epoch 36/50\n",
      "524/524 [==============================] - 0s 844us/step - loss: 0.7115 - acc: 0.7653 - val_loss: 2.7022 - val_acc: 0.2600\n",
      "Epoch 37/50\n",
      "524/524 [==============================] - 0s 845us/step - loss: 0.6252 - acc: 0.7844 - val_loss: 2.8817 - val_acc: 0.2571\n",
      "Epoch 38/50\n",
      "524/524 [==============================] - 0s 835us/step - loss: 0.5487 - acc: 0.8359 - val_loss: 2.7835 - val_acc: 0.2886\n",
      "Epoch 39/50\n",
      "524/524 [==============================] - 0s 829us/step - loss: 0.5870 - acc: 0.7939 - val_loss: 2.7216 - val_acc: 0.2686\n",
      "Epoch 40/50\n",
      "524/524 [==============================] - 0s 834us/step - loss: 0.4763 - acc: 0.8397 - val_loss: 2.9399 - val_acc: 0.2800\n",
      "Epoch 41/50\n",
      "524/524 [==============================] - 0s 839us/step - loss: 0.5707 - acc: 0.8130 - val_loss: 2.7491 - val_acc: 0.2514\n",
      "Epoch 42/50\n",
      "524/524 [==============================] - 0s 827us/step - loss: 0.4638 - acc: 0.8569 - val_loss: 2.8741 - val_acc: 0.2657\n",
      "Epoch 43/50\n",
      "524/524 [==============================] - 0s 860us/step - loss: 0.4714 - acc: 0.8550 - val_loss: 3.1048 - val_acc: 0.2657\n",
      "Epoch 44/50\n",
      "524/524 [==============================] - 0s 877us/step - loss: 0.4676 - acc: 0.8588 - val_loss: 3.1830 - val_acc: 0.2829\n",
      "Epoch 45/50\n",
      "524/524 [==============================] - 1s 982us/step - loss: 0.4357 - acc: 0.8702 - val_loss: 3.1653 - val_acc: 0.2229\n",
      "Epoch 46/50\n",
      "524/524 [==============================] - 1s 984us/step - loss: 0.4923 - acc: 0.8511 - val_loss: 3.0146 - val_acc: 0.2514\n",
      "Epoch 47/50\n",
      "524/524 [==============================] - 1s 974us/step - loss: 0.4007 - acc: 0.8855 - val_loss: 3.0099 - val_acc: 0.2543\n",
      "Epoch 48/50\n",
      "524/524 [==============================] - 0s 952us/step - loss: 0.3583 - acc: 0.9008 - val_loss: 3.2107 - val_acc: 0.2600\n",
      "Epoch 49/50\n",
      "524/524 [==============================] - 0s 837us/step - loss: 0.3722 - acc: 0.8969 - val_loss: 3.2725 - val_acc: 0.2200\n",
      "Epoch 50/50\n",
      "524/524 [==============================] - 0s 862us/step - loss: 0.3568 - acc: 0.8989 - val_loss: 3.3326 - val_acc: 0.2543\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x11ab155c0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:11.144528Z",
     "start_time": "2018-09-07T09:06:10.795028Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 220 into shape (1,20,9,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cbf770f33cd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/kingsleytorlowei/AnacondaProjects/Audio Analysis/processed wav/Nigerian/edo1.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ad27a4cf17c0>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(filepath, model)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav2mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0msample_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dim_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dim_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     return get_labels()[0][\n\u001b[1;32m     24\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 220 into shape (1,20,9,1)"
     ]
    }
   ],
   "source": [
    "print(predict('/Users/kingsleytorlowei/AnacondaProjects/Audio Analysis/processed wav/Nigerian/edo1.wav', model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:31.454484Z",
     "start_time": "2018-09-07T09:06:31.362508Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 220 into shape (1,20,9,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-ab6fea5ea0ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/Users/kingsleytorlowei/Desktop/New.wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-2-ad27a4cf17c0>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(filepath, model)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwav2mfcc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0msample_reshaped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dim_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_dim_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     return get_labels()[0][\n\u001b[1;32m     24\u001b[0m             \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_reshaped\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 220 into shape (1,20,9,1)"
     ]
    }
   ],
   "source": [
    "print(predict('/Users/kingsleytorlowei/Desktop/New.wav', model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:11.148100Z",
     "start_time": "2018-09-07T09:05:20.721Z"
    }
   },
   "outputs": [],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:11.150329Z",
     "start_time": "2018-09-07T09:05:20.726Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict('/Users/kingsleytorlowei/Desktop//Daniel.wav', model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:11.153404Z",
     "start_time": "2018-09-07T09:05:20.729Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict('/Users/kingsleytorlowei/Desktop/WhatsApp Ptt 2018-09-04 at 14.47.05.wav', model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:11.155907Z",
     "start_time": "2018-09-07T09:05:20.732Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict('/Users/kingsleytorlowei/Desktop/WhatsApp Ptt 2018-09-04 at 14.44.59.wav',model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:11.158352Z",
     "start_time": "2018-09-07T09:05:20.742Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict('/Users/kingsleytorlowei/Desktop/WhatsApp Ptt 2018-09-04 at 14.47.37.wav', model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:11.164620Z",
     "start_time": "2018-09-07T09:05:20.745Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict('/Users/kingsleytorlowei/Desktop/record20180904153041 - Rosebud Anwuri Raymond.wav', model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:11.166565Z",
     "start_time": "2018-09-07T09:05:20.748Z"
    }
   },
   "outputs": [],
   "source": [
    "print(predict('/Users/kingsleytorlowei/Desktop/record20180904175328 - Rosebud Anwuri Raymond.wav', model=model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-07T09:06:11.169811Z",
     "start_time": "2018-09-07T09:05:20.751Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
