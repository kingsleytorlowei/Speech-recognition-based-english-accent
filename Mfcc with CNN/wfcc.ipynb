{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T06:48:35.506693Z",
     "start_time": "2018-09-25T06:48:04.124637Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "Saving vectors of label - 'Dutch': 100%|██████████| 50/50 [00:02<00:00, 20.31it/s]\n",
      "Saving vectors of label - 'Australian': 100%|██████████| 40/40 [00:01<00:00, 25.01it/s]\n",
      "Saving vectors of label - 'Nigerian': 100%|██████████| 68/68 [00:03<00:00, 20.50it/s]\n",
      "Saving vectors of label - 'French': 100%|██████████| 68/68 [00:03<00:00, 22.52it/s]\n",
      "Saving vectors of label - 'Spanish': 100%|██████████| 59/59 [00:02<00:00, 21.77it/s]\n",
      "Saving vectors of label - 'British': 100%|██████████| 69/69 [00:02<00:00, 25.19it/s]\n",
      "Saving vectors of label - 'Chinese': 100%|██████████| 55/55 [00:02<00:00, 19.86it/s]\n",
      "Saving vectors of label - 'Canadian': 100%|██████████| 45/45 [00:01<00:00, 26.29it/s]\n",
      "Saving vectors of label - 'Arabic': 100%|██████████| 64/64 [00:03<00:00, 18.13it/s]\n",
      "Saving vectors of label - 'American': 100%|██████████| 68/68 [00:02<00:00, 26.73it/s]\n"
     ]
    }
   ],
   "source": [
    "#%load_ext autoreload\n",
    "#%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "from mfcc_pre_process import *\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Second dimension of the feature is dim2\n",
    "feature_dim_2 = 1378\n",
    "\n",
    "# Save data to array file first\n",
    "save_data_to_array(max_len=feature_dim_2)\n",
    "\n",
    "# # Loading train set and test set\n",
    "X_train, X_test, y_train, y_test = get_train_test()\n",
    "\n",
    "# # Feature dimension\n",
    "feature_dim_1 = 20\n",
    "channel = 1\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "verbose = 1\n",
    "num_classes = 10\n",
    "\n",
    "# Reshaping to perform 2D convolution\n",
    "X_train = X_train.reshape(X_train.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "X_test = X_test.reshape(X_test.shape[0], feature_dim_1, feature_dim_2, channel)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T06:48:35.517933Z",
     "start_time": "2018-09-25T06:48:35.509378Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size=(2, 2), activation='relu', input_shape=(feature_dim_1, feature_dim_2, channel)))\n",
    "    model.add(Conv2D(48, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(Conv2D(120, kernel_size=(2, 2), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.25))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "                  optimizer=keras.optimizers.Adadelta(),\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Predicts one sample\n",
    "def predict(filepath, model):\n",
    "    sample = wav2mfcc(filepath)\n",
    "    sample_reshaped = sample.reshape(1, feature_dim_1, feature_dim_2, channel)\n",
    "    return get_labels()[0][\n",
    "            np.argmax(model.predict(sample_reshaped))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T06:48:35.545285Z",
     "start_time": "2018-09-25T06:48:35.522728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((351, 20, 1378, 1), (235, 20, 1378, 1), (351, 10), (235, 10))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train_hot.shape, y_test_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-09-25T08:00:51.150439Z",
     "start_time": "2018-09-25T06:48:35.551299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 351 samples, validate on 235 samples\n",
      "Epoch 1/50\n",
      "351/351 [==============================] - 88s 252ms/step - loss: 3.3036 - acc: 0.1026 - val_loss: 2.3263 - val_acc: 0.0979\n",
      "Epoch 2/50\n",
      "351/351 [==============================] - 81s 230ms/step - loss: 2.3095 - acc: 0.1083 - val_loss: 2.3088 - val_acc: 0.1149\n",
      "Epoch 3/50\n",
      "351/351 [==============================] - 80s 228ms/step - loss: 2.2521 - acc: 0.1681 - val_loss: 2.2937 - val_acc: 0.1021\n",
      "Epoch 4/50\n",
      "351/351 [==============================] - 80s 229ms/step - loss: 2.2258 - acc: 0.1966 - val_loss: 2.2645 - val_acc: 0.1617\n",
      "Epoch 5/50\n",
      "351/351 [==============================] - 91s 259ms/step - loss: 2.2138 - acc: 0.1823 - val_loss: 2.2667 - val_acc: 0.1532\n",
      "Epoch 6/50\n",
      "351/351 [==============================] - 113s 322ms/step - loss: 2.2045 - acc: 0.1852 - val_loss: 2.2673 - val_acc: 0.1234\n",
      "Epoch 7/50\n",
      "351/351 [==============================] - 94s 268ms/step - loss: 2.1898 - acc: 0.1567 - val_loss: 2.2215 - val_acc: 0.1957\n",
      "Epoch 8/50\n",
      "351/351 [==============================] - 101s 287ms/step - loss: 2.0973 - acc: 0.2507 - val_loss: 2.2940 - val_acc: 0.1149\n",
      "Epoch 9/50\n",
      "351/351 [==============================] - 110s 313ms/step - loss: 2.1295 - acc: 0.1966 - val_loss: 2.2268 - val_acc: 0.1447\n",
      "Epoch 10/50\n",
      "351/351 [==============================] - 90s 256ms/step - loss: 2.1059 - acc: 0.2393 - val_loss: 2.2235 - val_acc: 0.1745\n",
      "Epoch 11/50\n",
      "351/351 [==============================] - 96s 275ms/step - loss: 2.0358 - acc: 0.2536 - val_loss: 2.4848 - val_acc: 0.1106\n",
      "Epoch 12/50\n",
      "351/351 [==============================] - 97s 276ms/step - loss: 2.2025 - acc: 0.1795 - val_loss: 2.2304 - val_acc: 0.1532\n",
      "Epoch 13/50\n",
      "351/351 [==============================] - 94s 268ms/step - loss: 2.0323 - acc: 0.2764 - val_loss: 2.2008 - val_acc: 0.1787\n",
      "Epoch 14/50\n",
      "351/351 [==============================] - 91s 259ms/step - loss: 1.9671 - acc: 0.3077 - val_loss: 2.2127 - val_acc: 0.1957\n",
      "Epoch 15/50\n",
      "351/351 [==============================] - 86s 246ms/step - loss: 1.8407 - acc: 0.3590 - val_loss: 2.1980 - val_acc: 0.2000\n",
      "Epoch 16/50\n",
      "351/351 [==============================] - 86s 245ms/step - loss: 1.8505 - acc: 0.3362 - val_loss: 2.2399 - val_acc: 0.1957\n",
      "Epoch 17/50\n",
      "351/351 [==============================] - 85s 242ms/step - loss: 1.8006 - acc: 0.3704 - val_loss: 2.3486 - val_acc: 0.1234\n",
      "Epoch 18/50\n",
      "351/351 [==============================] - 85s 244ms/step - loss: 1.8172 - acc: 0.3818 - val_loss: 2.3561 - val_acc: 0.1830\n",
      "Epoch 19/50\n",
      "351/351 [==============================] - 86s 246ms/step - loss: 1.7605 - acc: 0.3704 - val_loss: 2.2415 - val_acc: 0.1787\n",
      "Epoch 20/50\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 1.6725 - acc: 0.4103 - val_loss: 2.1959 - val_acc: 0.1745\n",
      "Epoch 21/50\n",
      "351/351 [==============================] - 77s 220ms/step - loss: 1.6329 - acc: 0.4302 - val_loss: 2.3486 - val_acc: 0.1574\n",
      "Epoch 22/50\n",
      "351/351 [==============================] - 78s 222ms/step - loss: 1.7462 - acc: 0.3846 - val_loss: 2.1355 - val_acc: 0.2511\n",
      "Epoch 23/50\n",
      "351/351 [==============================] - 78s 222ms/step - loss: 1.4511 - acc: 0.5014 - val_loss: 2.3495 - val_acc: 0.2000\n",
      "Epoch 24/50\n",
      "351/351 [==============================] - 79s 226ms/step - loss: 1.5583 - acc: 0.4387 - val_loss: 2.2422 - val_acc: 0.2043\n",
      "Epoch 25/50\n",
      "351/351 [==============================] - 76s 217ms/step - loss: 1.2771 - acc: 0.5897 - val_loss: 2.2401 - val_acc: 0.1702\n",
      "Epoch 26/50\n",
      "351/351 [==============================] - 95s 271ms/step - loss: 1.3213 - acc: 0.5726 - val_loss: 2.7574 - val_acc: 0.1362\n",
      "Epoch 27/50\n",
      "351/351 [==============================] - 84s 240ms/step - loss: 1.2490 - acc: 0.5926 - val_loss: 2.3238 - val_acc: 0.2298\n",
      "Epoch 28/50\n",
      "351/351 [==============================] - 95s 269ms/step - loss: 1.3004 - acc: 0.5755 - val_loss: 2.2423 - val_acc: 0.2255\n",
      "Epoch 29/50\n",
      "351/351 [==============================] - 81s 230ms/step - loss: 0.9223 - acc: 0.6638 - val_loss: 2.3138 - val_acc: 0.2426\n",
      "Epoch 30/50\n",
      "351/351 [==============================] - 79s 224ms/step - loss: 0.9438 - acc: 0.6838 - val_loss: 2.3400 - val_acc: 0.2809\n",
      "Epoch 31/50\n",
      "351/351 [==============================] - 82s 234ms/step - loss: 0.8403 - acc: 0.7066 - val_loss: 3.0367 - val_acc: 0.2043\n",
      "Epoch 32/50\n",
      "351/351 [==============================] - 83s 237ms/step - loss: 1.1989 - acc: 0.6239 - val_loss: 2.4244 - val_acc: 0.1915\n",
      "Epoch 33/50\n",
      "351/351 [==============================] - 82s 233ms/step - loss: 0.8335 - acc: 0.7123 - val_loss: 2.6580 - val_acc: 0.1702\n",
      "Epoch 34/50\n",
      "351/351 [==============================] - 80s 228ms/step - loss: 0.7404 - acc: 0.7350 - val_loss: 2.5993 - val_acc: 0.2383\n",
      "Epoch 35/50\n",
      "351/351 [==============================] - 83s 237ms/step - loss: 0.5798 - acc: 0.7892 - val_loss: 2.5193 - val_acc: 0.2766\n",
      "Epoch 36/50\n",
      "351/351 [==============================] - 80s 229ms/step - loss: 0.4393 - acc: 0.8575 - val_loss: 3.5664 - val_acc: 0.2085\n",
      "Epoch 37/50\n",
      "351/351 [==============================] - 82s 235ms/step - loss: 0.5339 - acc: 0.8291 - val_loss: 2.9905 - val_acc: 0.2085\n",
      "Epoch 38/50\n",
      "351/351 [==============================] - 79s 226ms/step - loss: 0.4758 - acc: 0.8348 - val_loss: 2.7221 - val_acc: 0.2340\n",
      "Epoch 39/50\n",
      "351/351 [==============================] - 81s 230ms/step - loss: 0.3851 - acc: 0.8746 - val_loss: 3.1882 - val_acc: 0.1830\n",
      "Epoch 40/50\n",
      "351/351 [==============================] - 81s 230ms/step - loss: 0.4454 - acc: 0.8433 - val_loss: 2.7515 - val_acc: 0.2340\n",
      "Epoch 41/50\n",
      "351/351 [==============================] - 86s 244ms/step - loss: 0.4475 - acc: 0.8632 - val_loss: 2.8352 - val_acc: 0.2553\n",
      "Epoch 42/50\n",
      "351/351 [==============================] - 102s 292ms/step - loss: 0.3635 - acc: 0.8775 - val_loss: 3.4542 - val_acc: 0.2128\n",
      "Epoch 43/50\n",
      "351/351 [==============================] - 91s 258ms/step - loss: 0.3342 - acc: 0.8889 - val_loss: 3.2775 - val_acc: 0.2255\n",
      "Epoch 44/50\n",
      "351/351 [==============================] - 86s 246ms/step - loss: 0.3388 - acc: 0.8832 - val_loss: 3.1428 - val_acc: 0.2383\n",
      "Epoch 45/50\n",
      "351/351 [==============================] - 86s 245ms/step - loss: 0.3168 - acc: 0.8974 - val_loss: 3.6063 - val_acc: 0.1915\n",
      "Epoch 46/50\n",
      "351/351 [==============================] - 83s 236ms/step - loss: 0.2935 - acc: 0.8946 - val_loss: 2.9132 - val_acc: 0.2383\n",
      "Epoch 47/50\n",
      "351/351 [==============================] - 84s 239ms/step - loss: 0.2993 - acc: 0.8974 - val_loss: 3.3527 - val_acc: 0.2170\n",
      "Epoch 48/50\n",
      "351/351 [==============================] - 84s 238ms/step - loss: 0.3160 - acc: 0.8917 - val_loss: 3.4429 - val_acc: 0.1957\n",
      "Epoch 49/50\n",
      "351/351 [==============================] - 90s 257ms/step - loss: 0.2918 - acc: 0.9174 - val_loss: 3.3133 - val_acc: 0.2298\n",
      "Epoch 50/50\n",
      "351/351 [==============================] - 90s 257ms/step - loss: 0.2752 - acc: 0.9060 - val_loss: 3.3599 - val_acc: 0.2468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x106eff9e8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.fit(X_train, y_train_hot, batch_size=batch_size, epochs=epochs, verbose=verbose, validation_data=(X_test, y_test_hot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
